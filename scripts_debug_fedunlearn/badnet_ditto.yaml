attack:
  attack_method: backdoor
  attacker_id: 1
  attackers_list: [1, 2, 3, 4, 5]
  freq: 3
  label_type: dirty
  mean: [0.4914, 0.4822, 0.4465]
  poison_ratio: 0.1
  scale_para: 3.0
  setting: random
  std: [0.247, 0.2435, 0.2616]
  target_label_ind: 7
  trigger_type: squareTrigger
  use_multi_attackers: true
criterion: {type: CrossEntropyLoss}
data:
  args:
  - {download: true}
  batch_size: 64
  dataset: [train, val, test, poison]
  num_workers: 0
  root: data/
  splits: [1.0, 0.0, 0.0]
  splitter: lda
  splitter_args:
  - {alpha: 0.5}
  transform:
  - [ToTensor]
  type: CIFAR10@torchvision
device: 1
early_stop: {patience: 0}
eval:
  best_res_update_round_wise_key: test_loss
  freq: 100
  metrics: [acc, correct]
  split: [test, poison]
expname: badnet_ditto
federate: {batch_or_epoch: epoch, client_num: 10, local_update_steps: 2, make_global_eval: false,
  method: Ditto, mode: standalone, sample_client_rate: 0.5, total_round_num: 100}
grad: {grad_clip: 5.0}
model: {dropout: 0.0, hidden: 512, out_channels: 10, type: convnet2}
optimizer: {lr: 0.1, weight_decay: 0.0}
outdir: debug-output/
seed: 12345
trainer: {type: cvtrainer}
use_gpu: true
verbose: 1
