attack:
  attack_method: backdoor
  attacker_id: 4
  freq: 3
  label_type: clean
  mean: [0.4914, 0.4822, 0.4465]
  poison_ratio: 0.05
  setting: fix
  std: [0.247, 0.2435, 0.2616]
  target_label_ind: 2
  trigger_type: signalTrigger
criterion: {type: CrossEntropyLoss}
data:
  args:
  - {download: true}
  batch_size: 64
  dataset: [train, val, test, poison]
  num_workers: 0
  root: data/
  splits: [1.0, 0.0, 0.0]
  splitter: lda
  splitter_args:
  - {alpha: 0.5}
  transform:
  - [ToTensor]
  type: CIFAR10@torchvision
device: 0
early_stop: {patience: 0}
eval:
  best_res_update_round_wise_key: test_loss
  freq: 100
  metrics: [acc, correct]
  split: [test, poison]
expname: narci_fedunlearn
federate: {batch_or_epoch: epoch, client_num: 100, local_update_steps: 2, make_global_eval: false,
  method: FedUnlearn, mode: standalone, sample_client_rate: 0.1, total_round_num: 100}
fedunlearn: {loss_thresh: 0.5, switch_rounds: 6, trap_rate: 0.05}
grad: {grad_clip: 5.0}
model: {dropout: 0.0, hidden: 512, out_channels: 10, type: convnet2}
optimizer: {lr: 0.1, weight_decay: 0.0}
outdir: debug-output/
seed: 12345
trainer: {type: cvtrainer}
use_gpu: true
verbose: 1
