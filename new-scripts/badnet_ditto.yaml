attack:
  attack_method: backdoor
  attacker_id: 1
  freq: 3
  label_type: dirty
  mean: [0.4914, 0.4822, 0.4465]
  poison_ratio: 0.4
  setting: fix
  std: [0.247, 0.2435, 0.2616]
  target_label_ind: 7
  trigger_type: squareTrigger
criterion: {type: CrossEntropyLoss}
data:
  args:
  - {download: true}
  num_workers: 0
  root: data/
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args:
  - {alpha: 0.5}
  test_transform:
  - [ToTensor]
  - - Normalize
    - mean: [0.4914, 0.4822, 0.4465]
      std: [0.247, 0.2435, 0.2616]
  transform:
  - [ToTensor]
  - - Normalize
    - mean: [0.4914, 0.4822, 0.4465]
      std: [0.247, 0.2435, 0.2616]
  type: CIFAR10@torchvision
dataloader: {batch_size: 64}
device: 0
early_stop: {patience: 0}
eval:
  best_res_update_round_wise_key: test_loss
  freq: 1
  metrics: [acc, correct]
  split: [test, val]
expname_tag: badnet_ditto
federate: {client_num: 100, make_global_eval: false, merge_test_data: false, method: Ditto,
  mode: standalone, sample_client_rate: 0.1, total_round_num: 500}
grad: {grad_clip: 5.0}
model: {dropout: 0.0, hidden: 2048, out_channels: 10, type: convnet2}
outdir: new-output/
seed: 12345
train:
  batch_or_epoch: epoch
  local_update_steps: 1
  optimizer: {lr: 0.1, weight_decay: 0.0}
trainer: {type: cvtrainer}
use_gpu: true
verbose: 1
