
program: /mnt1/daoyuanchen.cdy/FederatedScope/federatedscope/main.py
project: pFL-bench
name: isolated-train,FEMNIST
method: grid
#method: bayes
metric:
  goal: maximize
  name: best_client_summarized_weighted_avg/val_acc
command:
  - /usr/bin/env # ${env}
  - /mnt1/daoyuanchen.cdy/anaconda3/envs/gfl/bin/python   # ${interpreter}
  - ${program}
  - "--cfg"
  - "/mnt1/daoyuanchen.cdy/FederatedScope/scripts/personalization_exp_scripts/pfl_bench/FEMNIST/fedavg_convnet2_on_femnist.yaml"
  - "outdir"
  - "exp_pfl_bench"
  - "wandb.use"
  - "True"
  - "wandb.name_project"
  - "pFL-bench"
  - "wandb.name_user"
  - "daoyuan"
  - "expname_tag"
  - "local_train"
  - "federate.method"
  - "local"
  - ${args_no_hyphens}
parameters:
  optimizer.lr:
    values: [0.05, 0.005, 0.5, 0.01, 0.1]
  federate.local_update_steps:
    values: [1, 3]

early_terminate:
  type: hyperband
  min_iter: 3  # the first bucket indicates we called wandb at least 3 times

# TODO: list all the yaml, pre-calculate the costs and missing baselines and datasets, currently, we can use the cv data, nlp data + gfl data, speech and rec can be misc type